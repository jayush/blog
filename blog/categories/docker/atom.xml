<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | SequenceIQ Blog]]></title>
  <link href="http://blog.sequenceiq.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://blog.sequenceiq.com/"/>
  <updated>2014-08-16T20:50:31+00:00</updated>
  <id>http://blog.sequenceiq.com/</id>
  <author>
    <name><![CDATA[SequenceIQ]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Apache Hadoop 2.5.0 on Docker]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/08/19/hadoop-2-5-0-docker/"/>
    <updated>2014-08-19T18:07:18+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/08/19/hadoop-2-5-0-docker</id>
    <content type="html"><![CDATA[<p>A few weeks ago we have released an Apache Hadoop 2.3 Docker image &ndash; in a very short time this become the most <a href="https://registry.hub.docker.com/search?q=hadoop&amp;s=downloads">popular</a> Hadoop image in the Docker <a href="https://registry.hub.docker.com/">registry</a>.</p>

<p>Following on the success of our Hadoop 2.3.0, 2.4.0 and 2.4.1 Docker <a href="https://registry.hub.docker.com/u/sequenceiq/hadoop-docker/">image</a>, the feedbacks and requests we have received and aligning with the Hadoop release cycle, we have released an Apache Hadoop 2.5.0 Docker image &ndash; same as the previous version this is available as a trusted and automated build on the official Docker <a href="https://registry.hub.docker.com/">registry</a>.</p>

<p>Please note that beside this Hadoop image, we have released and maintain a <a href="http://blog.sequenceiq.com/blog/2014/06/17/ambari-cluster-on-docker/">pseudo-distributed</a> and <a href="http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">distributed</a> Hadoop Docker image provisioned with Apache Ambari. As they are provisioned with Ambari you have the option to change, add and remove Hadoop components using cluster blueprints.</p>

<p>Also we are happy to let you know that this release of Apache Hadoop contains a few of our open source <strong>contributions</strong> and <a href="https://issues.apache.org/jira/browse/YARN-2250">fixes</a> around YARN schedulers.
We are working on an SLA enforcer for Hadoop &ndash; very soon to be open sourced &ndash; and part of that work we are contributing back to the community. Also there is a major contribution of ours coming in the next release of Hadoop &ndash; 2.6.0.
Stay tuned and follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>

<h2>Build the image</h2>

<p>In case you&rsquo;d like to try directly from the <a href="https://github.com/sequenceiq/hadoop-docker">Dockerfile</a> you can build the image as:</p>

<p><code>
docker build  -t sequenceiq/hadoop-docker .
</code></p>

<!-- more -->


<h2>Pull the image</h2>

<p>As it is also released as an official Docker image from Docker&rsquo;s automated build repository &ndash; you can always pull or refer the image when launching containers.</p>

<p><code>
docker pull sequenceiq/hadoop-docker:2.5.0
</code></p>

<h2>Start a container</h2>

<p>In order to use the Docker image you have just build or pulled use:</p>

<p><code>
docker run -i -t sequenceiq/hadoop-docker:2.5.0 /etc/bootstrap.sh -bash
</code></p>

<h2>Testing</h2>

<p>You can run one of the stock examples:</p>

<p>```
cd $HADOOP_PREFIX</p>

<h1>run the mapreduce</h1>

<p>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar grep input output &lsquo;dfs[a-z.]+&rsquo;</p>

<h1>check the output</h1>

<p>bin/hdfs dfs -cat output/*
```</p>

<h2>Hadoop native libraries, build, Bintray, etc</h2>

<p>The Hadoop build process is no easy task &ndash; requires lots of libraries and their right version, protobuf, etc and takes some time &ndash; we have simplified all these, made the build and released a 64b version of Hadoop nativelibs on our <a href="https://bintray.com/sequenceiq/sequenceiq-bin/hadoop-native-64bit/2.4.1/view/files">Bintray repo</a>. Enjoy.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker intercontainer networking explained]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/08/12/docker-networking/"/>
    <updated>2014-08-12T08:53:15+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/08/12/docker-networking</id>
    <content type="html"><![CDATA[<p>The purpose of this blog entry is to cover advanced topics regarding Docker networking and explain different concepts to inter-connect Docker containers when the containers are running on different host machines.
For the demonstration we are using VMs on <a href="https://www.virtualbox.org/">VirtualBox</a> launched with <a href="http://www.vagrantup.com/">Vagrant</a>, but the explained networking concepts work also on Amazon EC2 (with VPC) and Azure unless stated otherwise.</p>

<p>To set up the the test environment clone the <a href="https://github.com/sequenceiq/sequenceiq-samples">SequenceIQ&rsquo;s samples repository</a> and follow the instructions.</p>

<p><code>
git clone git@github.com:sequenceiq/sequenceiq-samples.git
cd sequenceiq-samples/docker-networking
vagrant up
</code></p>

<p>The <code>vagrant up</code> command launches the test setup, which conatins two Ubuntu 14.04 VMs with the network configuration:</p>

<ul>
<li><a href="https://www.virtualbox.org/manual/ch06.html#network_nat">NAT</a></li>
<li><a href="https://docs.vagrantup.com/v2/networking/private_network.html">Private networking</a></li>
</ul>


<p>The NAT (related to eth0 interface on VMs) is used only for access the external network from VMs e.g. download files from debian repository, but it is not used for inter-container communication. The Vagrant sets up a properly configured Host Only Networking in VirtualBox therefore the VMs can communicate with each other on the defined IP addresses:</p>

<ul>
<li>vm1: 192.168.40.11</li>
<li>vm2: 192.168.40.12</li>
</ul>


<p>Let&rsquo;s see how Docker containers running on these VMs can send IP packets to each other.</p>

<!--more-->


<h2>Setting up bridge0</h2>

<p>The Docker attaches all containers to the virtual subnet implemented by docker0, this means that by default on both VMs the Docker containers will be launched with IP addresses from range 172.17.42.1/24. This is a problem for some of the solutions explained below, because if the containers on different hosts have the same IP addresses then we won&rsquo;t be able to properly route the IP packets between them. Therefore on each VMs a network bridge is created with the following subnets:</p>

<ul>
<li>vm1: 172.17.51.1/24</li>
<li>vm2: 172.17.52.1/24</li>
</ul>


<p>This means that every container luanched on vm1 will get an IP address from range 172.17.51.2 &ndash; 172.17.51.255 and containers on vm2 will have an address from range 172.17.52.2 &ndash; 172.17.52.255.</p>

<p>```bash</p>

<h1>do not execute, it was already executed on vm1 as root during provision from Vagrant</h1>

<p>brctl addbr bridge0
sudo ifconfig bridge0 172.17.51.1 netmask 255.255.255.0
sudo bash -c &lsquo;echo DOCKER_OPTS=\&ldquo;-b=bridge0\&rdquo; >> /etc/default/docker&rsquo;
sudo service docker restart</p>

<h1>do not execute, it was already executed on vm1 as root during provision from Vagrant</h1>

<p>sudo brctl addbr bridge0
sudo ifconfig bridge0 172.17.52.1 netmask 255.255.255.0
sudo bash -c &lsquo;echo DOCKER_OPTS=\&ldquo;-b=bridge0\&rdquo; >> /etc/default/docker&rsquo;
sudo service docker restart
```</p>

<p>As noted in the comments the above configuration is already executed during the provisioning of VMs and it was copied here just for the sake of clarity and completeness.</p>

<h2>Expose container ports to host</h2>

<p>Probably the simplest way to solve inter-container communication is to expose ports from container to the host. This can be done with the <code>-p</code> switch. E.g. exposing the port 3333 is as simple as:</p>

<p>```bash</p>

<h1>execute on vm1</h1>

<p>sudo docker run -it &mdash;rm &mdash;name cont1 -p 3333:3333 ubuntu /bin/bash -c &ldquo;nc -l 3333&rdquo;</p>

<h1>execute on vm2</h1>

<p>sudo docker run -it &mdash;rm &mdash;name cont2 ubuntu /bin/bash -c &ldquo;nc -w 1 -v 192.168.40.11 3333&rdquo;</p>

<h1>Result: Connection to 192.168.40.11 3333 port [tcp/*] succeeded!</h1>

<p>```</p>

<p>This might be well suited for cases when the communication ports are defined in advance (e.g. MySQL will run on port 3306), but will not work when the application uses dynamic ports for communication (like Hadoop does with IPC ports).</p>

<h2>Host networking</h2>

<p>If the container is started with <code>--net=host</code> then it avoids placing the container inside of a separate network stack, but as the Docker documentation says this option &ldquo;tells Docker to not containerize the container&rsquo;s networking&rdquo;. The <code>cont1</code> container can bind directly to the network interface of host therefore the <code>nc</code> will be available directly on 192.168.40.11.</p>

<p>```bash</p>

<h1>execute on vm1</h1>

<p>sudo docker run -it &mdash;rm &mdash;name cont1 &mdash;net=host ubuntu /bin/bash -c &ldquo;nc -l 3333&rdquo;</p>

<h1>execute on vm2</h1>

<p>sudo docker run -it &mdash;rm &mdash;name cont2 ubuntu /bin/bash -c &ldquo;nc -w 1 -v 192.168.40.11 3333&rdquo;</p>

<h1>Result: Connection to 192.168.40.11 3333 port [tcp/*] succeeded!</h1>

<p>```</p>

<p>Of course if you want to access cont2 from cont1 then cont2 also needs to be started with <code>--net=host</code> option.
The host networking is very powerful solution for inter-container communication, but it has its drawbacks, since the ports used by the container can collide with the ports used by host or other containers utilising &mdash;net=host option, because all of them are sharing the same network stack.</p>

<h2>Direct Routing</h2>

<p>So far we have seen methods where the containers have used the IP address of host to communicate with each other, but there are solutions to inter-connect the containers by using their own IPs. If we are using the containers own IPs for routing then it is important that we shall be able to distinguish based on IP which container is running on vm1 and which one is running on on vm2, this was the reason why the bridge0 interface was created as explained in &ldquo;Setting up bridge0&rdquo; section.
To make the things a bit easier to understand I have created a simplified diagram of the network interfaces in our current test setup. If I would like to oversimplify the thing then I would say that, we shall setup the routing in that way that the packets from one container are following the red lines shown on the diagram.</p>

<p style="text-align:center;"> <img class="<a" src="href="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/docker-networking/img/routing.png">https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/docker-networking/img/routing.png</a>"></p>

<p>To achive this we need to configure the routing table on hosts in that way that every packet which destination is 172.17.51.0/24 is forwarded to vm1 and every IP packet where the destination is 172.17.52.0/24 is forwarded to vm2. To repeat it shortly, the containers running on vm1 are placed to subnet 172.17.51.0/24, containers on vm2 are on subnet 172.17.52.0/24.</p>

<p>```bash</p>

<h1>execute on vm1</h1>

<p>sudo route add -net 172.17.52.0 netmask 255.255.255.0 gw 192.168.40.12
sudo iptables -t nat -F POSTROUTING
sudo iptables -t nat -A POSTROUTING -s 172.17.51.0/24 ! -d 172.17.0.0/16 -j MASQUERADE
sudo docker run -it &mdash;rm &mdash;name cont1  ubuntu /bin/bash</p>

<h1>Inside the container (cont1)</h1>

<p>nc -l 3333</p>

<h1>execute on vm2</h1>

<p>sudo route add -net 172.17.51.0  netmask 255.255.255.0  gw 192.168.40.11
sudo iptables -t nat -F POSTROUTING
sudo iptables -t nat -A POSTROUTING -s 172.17.52.0/24 ! -d 172.17.0.0/16 -j MASQUERADE
sudo docker run -it &mdash;rm &mdash;name cont2  ubuntu /bin/bash</p>

<h1>Inside the container (cont2)</h1>

<p>nc -w 1 -v 172.17.51.2 3333</p>

<h1>Result: Connection to 172.17.51.2 3333 port [tcp/*] succeeded!</h1>

<p>```</p>

<p>The <code>route add</code> command adds the desired routing to the route table, but you might wonder why the iptables configuration is necessary. The reason for that the Docker by default sets up a rule to the nat table to masquerade all IP packets that are leaving the machine. In our case we definitely don&rsquo;t want this, therefore we delete all MASQUERADE rules with -F option. At this point we already would be able to make the connection from one container to other and vice verse, but the containers would not be able to communicate with the outside world, therefore an iptables rule needs to be added to masquerade the packets that are going outside of 172.17.0.0/16. I need to mention the another approach would be to use the <a href="https://docs.docker.com/articles/networking/#between-containers">&mdash;iptables=false</a> option of the daemon to avoid any manipulation in the iptables and you can do all the config manually.</p>

<p>Such kind of direct routing from one vm to other vm works great and easy to set up, but cannot be used if the hosts are not on the same subnet. If the host are located the on different subnet the tunneling might be an option as you will see it in the next section.</p>

<p><em>Note: This solution works on Amazon EC2 instances only if the <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_NAT_Instance.html#EIP_Disable_SrcDestCheck">Source/Destionation Check</a> is disabled.</em></p>

<p><em>Note: Due to the packet filtering policy of Azure this method cannot be used there.</em></p>

<h2>Generic Routing Encapsulation (GRE) tunnel</h2>

<p>GRE is a tunneling protocol that can encapsulate a wide variety of network layer protocols inside virtual point-to-point links.
The main idea is to create a GRE tunnel between the VMs and send all traffic through it:</p>

<p style="text-align:center;"> <img class="<a" src="href="https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/docker-networking/img/gre.png">https://raw.githubusercontent.com/sequenceiq/sequenceiq-samples/master/docker-networking/img/gre.png</a>"></p>

<p>In order to create a tunnel you need to specify the name, the type (which is gre in our case) and the IP address of local and the remote end. Consequently the tun2 name used for the tunnel on on vm1 since from vm1 perspective that is the tunnel endpoint which leads to vm2 and every packet sent to tun2 to will eventually come out on vm2 end.</p>

<p>```bash</p>

<h1>GRE tunnel config execute on vm1</h1>

<p>sudo iptunnel add tun2 mode gre local 192.168.40.11 remote 192.168.40.12
sudo ifconfig tun2 10.0.201.1
sudo ifconfig tun2 up
sudo route add -net 172.17.52.0 netmask 255.255.255.0 dev tun2
sudo iptables -t nat -F POSTROUTING
sudo iptables -t nat -A POSTROUTING -s 172.17.51.0/24 ! -d 172.17.0.0/16 -j MASQUERADE
sudo docker run -it &mdash;rm &mdash;name cont1  ubuntu /bin/bash</p>

<h1>Inside the container (cont1)</h1>

<p>nc -l 3333</p>

<h1>GRE tunnel config execute on vm2</h1>

<p>sudo iptunnel add tun1 mode gre local 192.168.40.12 remote 192.168.40.11
sudo ifconfig tun1 10.0.202.1
sudo ifconfig tun1 up
sudo route add -net 172.17.51.0 netmask 255.255.255.0 dev tun1
sudo iptables -t nat -F POSTROUTING
sudo iptables -t nat -A POSTROUTING -s 172.17.52.0/24 ! -d 172.17.0.0/16 -j MASQUERADE
sudo docker run -it &mdash;rm &mdash;name cont2  ubuntu /bin/bash</p>

<h1>Inside the container (cont2)</h1>

<p>nc -w 1 -v 172.17.51.2 3333</p>

<h1>Result: Connection to 172.17.51.2 3333 port [tcp/*] succeeded!</h1>

<p>```</p>

<p>After the tunnel is set up and activated the remaining commands are very similar to the commands executed in the &ldquo;Direct Routing&rdquo; section. The main difference here is that we do not route the traffic directly to other vm, but we are routing it into <code>dev tun1</code> and <code>dev tun2</code> respectively.</p>

<p>With GRE tunnels a point-to-point connection is set up between two hosts, which means that if you have more then two hosts in your network and want to interconnect all of them, then n-1 tunnel endpoint needs to be created on every host, which will be quite challenging to maintain if you have a large cluster.</p>

<p><em>Note: GRE packets are <a href="http://msdn.microsoft.com/en-us/library/azure/dn133803.aspx">filtered out</a> on Azure therefore this solution cannot be used there.</em></p>

<h2>Virtual Private Network (VPN)</h2>

<p>If more secured connections is required between containers then VPNs can be used on VMs. This addiotional security might significantly increase processing overhead. This overhead is highly depends on which VPN solution are you going to use. In this demo we use the VPN capabilities of SSH which is not really suited for production use. In order to enable the VPN capabilites of ssh the  PermitTunnel parameter needs to be switched on in sshd_config. If you are using the Vagranfile provided to this tutorial then nothing needs to be done, since this parameter was already set up for you during provisioning in the bootstrap.sh.</p>

<p>```bash</p>

<h1>execute on vm1</h1>

<p>sudo ssh -f -N -w 2:1 <a href="&#109;&#97;&#x69;&#108;&#116;&#x6f;&#58;&#114;&#x6f;&#111;&#x74;&#64;&#x31;&#57;&#50;&#x2e;&#49;&#x36;&#56;&#x2e;&#52;&#x30;&#x2e;&#x31;&#50;">&#114;&#x6f;&#111;&#116;&#64;&#49;&#57;&#50;&#x2e;&#49;&#x36;&#x38;&#x2e;&#x34;&#48;&#x2e;&#49;&#50;</a>
sudo ifconfig tun2 up
sudo route add -net 172.17.52.0 netmask 255.255.255.0 dev tun2
sudo iptables -t nat -F POSTROUTING
sudo iptables -t nat -A POSTROUTING -s 172.17.51.0/24 ! -d 172.17.0.0/16 -j MASQUERADE
sudo docker run -it &mdash;rm &mdash;name cont1  ubuntu /bin/bash</p>

<h1>Inside the container (cont1)</h1>

<p>nc -l 3333</p>

<h1>execute on vm2</h1>

<p>sudo ifconfig tun1 up
sudo route add -net 172.17.51.0 netmask 255.255.255.0 dev tun1
sudo iptables -t nat -F POSTROUTING
sudo iptables -t nat -A POSTROUTING -s 172.17.52.0/24 ! -d 172.17.0.0/16 -j MASQUERADE
sudo docker run -it &mdash;rm &mdash;name cont2  ubuntu /bin/bash</p>

<h1>Inside the container (cont2)</h1>

<p>nc -w 1 -v 172.17.51.2 3333</p>

<h1>Result: Connection to 172.17.51.2 3333 port [tcp/*] succeeded!</h1>

<p>```</p>

<p>The ssh is launched with -w option where the numerical ids of tun devices were specified. After executing the command the tunnel interfaces are created on both VMs. The interfaces needs to be be activated with ifconfig up and after that we need to setup the rooting to direct the traffic to  172.17.51.0/24 and 172.17.52.0/24 to tun2 and tun1.</p>

<p>As mentioned the VPN capabilities of SSH is not recommended in production, but other solutions like  <a href="https://openvpn.net/index.php/open-source.html">OpenVPN</a> would worth a try to secure the communication between the hosts (and also between the containers).</p>

<h2>Conclusion</h2>

<p>The above examples were hand written mainly for demonstration purposes, but there are great tools like <a href="https://github.com/jpetazzo/pipework">Pipework</a> that can make your life simpler and will do the heavy lifting for you.</p>

<p>If you want to check how these methods are working in production environment you are just a few clicks from it, since under the hood these methods are responsible to solve the inter-container communication in our cloud agnostic Hadoop as a Service API called <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak</a>.</p>

<p>For updates follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Launch Docker containers on Azure]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/08/04/launch-docker-containers-on-azure/"/>
    <updated>2014-08-04T19:43:01+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/08/04/launch-docker-containers-on-azure</id>
    <content type="html"><![CDATA[<p>Two weeks ago we have open sourced our cloud agnostic and Docker based Hadoop as a Service API &ndash; called <a href="http://sequenceiq.com/cloudbreak">Cloudbreak</a>.
The first public beta version supports Amazon’s AWS and Microsoft’s Azure, while we are already wrapping up a few new cloud provider integrations.</p>

<p>While there is some documentation about running Docker containers on Amazon, there is no detailed description about running Docker on the Azure cloud.
With this blog post we would like to shed some light on it &ndash; recently there have been lots of announcements from Microsoft about Docker support (Azure CLI, Kubernetes, libswarm) but they are either not finished yet or are not ready to build a robust platform on top.
We are eagerly waiting for the <a href="http://azure.microsoft.com/blog/2014/07/10/azure-collaboration-with-google-and-docker/">Kubernetes integration</a>.</p>

<p>In the meantime, if you are interested in running a <code>cluster</code> of Docker container, or do some more complex stuff then read on.</p>

<p>Just to briefly recap &ndash; with Cloudbreak we are launching on demand Hadoop clusters (check our <a href="http://blog.sequenceiq.com/blog/2014/07/25/cloudbreak-technology/">blog</a> for further technical details) in Docker containers. These containers are <code>shipped</code> to different cloud VMsm and dynamically find and join each other &ndash; they form a fully functional Hadoop cluster without the need to do anything manually on the host, or apply any manual pre-configuration.
So how are we doing this?</p>

<!--more-->


<h3>Docker ready base VM image</h3>

<p>First of all you need a base image with Docker installed &ndash; thus for that we have built and made available an Ubuntu 14.04 image with Docker installed. Apart from Docker, to build a fully dynamic and <code>service discovery</code> aware Docker cluster we needed <a href="http://stedolan.github.io/jq/">jq</a> and <a href="http://www.linuxfromscratch.org/blfs/view/svn/basicnet/bridge-utils.html"> bridge-utils</a>.</p>

<p>Once this base image is created you will need to make it public and re-usable. In order to do that the image has to be published in <a href="http://vmdepot.msopentech.com/List/Index">VMdepot</a>. When you are about to use an image from VM depot, and create a VM based on that you will need to copy it in your own storage account &ndash; note that doing it at first time this can be a slow process (20-25 minutes, copying the 30 GB image).</p>

<h3>Dynamic networking</h3>

<p>Now you have an image based on that you can launch your own VMs, and the Docker container inside your VM. While there are a few options to do that, we needed to find a unified way to do so &ndash; note that  <a href="http://sequenceiq.com/cloudbreak">Cloudbreak</a> is a cloud agnostic solution &ndash; and we do not want to create init scripts for each and every cloud environment we use. Amazon’s AWS has a feature so called <code>userdata</code> &ndash; an option of passing data to the instance that can be used to perform common automated configuration tasks and even run scripts after the instance starts. You can pass two types of user data to Amazon AWS: shell scripts and cloud-init directives. In order to keep the launch process unified everywhere we are using <a href="https://help.ubuntu.com/community/CloudInit">cloud-init</a> on Azure as well.</p>

<p>You can use/start Docker with different networking setup &ndash; using a bridged network or using the host network. You can check the init scripts in our <a href="https://github.com/sequenceiq/cloudbreak/blob/master/src/main/resources/azure-init.sh">GitHub</a> repository.</p>

<p><strong>Bridged network</strong></p>

<p>```bash</p>

<h1>set bridge0 in docker opts</h1>

<p>sh -c &ldquo;cat > /etc/default/docker&rdquo; &lt;&lt;&ldquo;EOF&rdquo;
DOCKER_OPTS=&ldquo;-b bridge0 -H unix:// -H tcp://0.0.0.0:2375&rdquo;
EOF</p>

<p>CMD=&ldquo;docker run -d -p SOURCE_PORT:DESTINATION_PORT 0 -e SERF_JOIN_IP=$SERF_JOIN_IP -e SERF_ADVERTISE_IP=$MY_IP &mdash;dns 127.0.0.1 &mdash;name ${NODE_PREFIX}${INSTANCE_IDX} -h ${NODE_PREFIX}${INSTANCE_IDX}.${MYDOMAIN} &mdash;entrypoint /usr/local/serf/bin/start-serf-agent.sh  $IMAGE $AMBARI_ROLE&rdquo;</p>

<p>```
<strong>Host network</strong></p>

<p><code>bash
CMD="docker run -d -e SERF_JOIN_IP=$AMBARI_SERVER_IP --net=host --name ${NODE_PREFIX}${INSTANCE_IDX} --entrypoint /usr/local/serf/bin/start-serf-agent.sh  $IMAGE $AMBARI_ROLE"
</code></p>

<p><em>Note: for cloud based clusters we are giving up on the bridged based network &ndash; mostly due to Azure&rsquo;s networking limitations &ndash; and will use the <code>net=host</code> solution in the next release. The bridged network will still be a supported solution, though we are using it mostly with bare metal or multi container/host solutions.</em></p>

<p>Azure has (comparing with Amazon’s AWS or Google’s Cloud compute) an <code>uncommon</code> network setup and supports limited flexibility &ndash; in order to overcome these, and still have a dynamic Hadoop cluster different scenarios / use cases requires different Docker networking &ndash; that is quite a large <strong>undocumented</strong> topic which we will cover in our next blog posts &ndash; in particular the issues, differences and solutions to use Docker on different cloud providers. While we have briefly talked about <a href="http://sequenceiq.com/cloudbreak/#technology">Serf</a> in the <a href="https://cloudbreak.sequenceiq.com">Cloudbreak</a> documentation, we will enter in deep technical details in one of our next posts as well. Should you be interested in these, make sure you follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook">Facebook</a> for updates.</p>

<h3>SequenceIQ’s Azure REST API &ndash; open sourced</h3>

<p>At <a href="htp://sequenceiq.com">SequenceIQ</a> we always automate everything &ndash; and in order to launch VM instances, configure networks, start containers, etc we needed a REST client which we can use it from our JAVA and Scala codebase. Since the Microsoft API is XML based &ndash; <em>yo, it’s 2014</em> &ndash; we have created and open sourced a Groovy based <a href="https://github.com/sequenceiq/azure-rest-client">Azure REST API</a> &ndash; wrapping the XML calls into a nice, easy to use and clean REST API. Feel free to use it &ndash; it’s open sourced under an Apache 2 license. Note that <a href="https://cloudbreak.sequenceiq.com">Cloudbreak</a> does not store your Azure user credential &ndash; whereas with the defulat Azue CLI that would have been possible &ndash; the only thing we need from your side to work is your subscription id. The process is documented here: <a href="http://sequenceiq.com/cloudbreak/#accounts.">http://sequenceiq.com/cloudbreak/#accounts.</a></p>

<h3>Metadata service for Azure</h3>

<p>The another nice feature we have created for Azure VMs is a <code>metadata service</code>. While a service as such does exists on Amazon’s AWS it’s missing from Microsoft Azure &ndash; note that our Cloudbreak solution is a cloud agnostic one, and we always strive to use identical solution on all cloud providers. The instance metadata is data about your instance that you can use to configure or manage the running instances &ndash; and available via a REST call. We have developed a service as such for Azure &ndash; <a href="https://github.com/sequenceiq/cloudbreak/blob/master/src/main/java/com/sequenceiq/cloudbreak/service/stack/connector/azure/AzureMetadataSetup.java">AzureMetadataSetup</a>. As you can see we collect the metadata, and make it available under a <code>unique hash</code> for each cluster by calling the following resource: <code>/metadata/{hash}</code></p>

<p>```java
private Set<CoreInstanceMetaData> collectMetaData(Stack stack, AzureClient azureClient, String name) {</p>

<pre><code>... try {
            CoreInstanceMetaData instanceMetaData = new CoreInstanceMetaData(vmName,
                    getPrivateIP((String) virtualMachine),
                    getVirtualIP((String) virtualMachine));
            instanceMetaDatas.add(instanceMetaData);
        } catch (IOException e) { ...
</code></pre>

<p>}
```
This service is used in a few cases &ndash; for example to learn different network setups as the hosts are using different network options than the Docker containers.</p>

<p>As usual for us &ndash; being committed to 100% open source &ndash; we are always open sourcing everything thus you can get the details on our <a href="https://github.com/sequenceiq/cloudbreak">GitHub</a> repository.
Should you have any questions feel free to engage with us on our <a href="http://blog.sequenceiq.com/">blog</a> or follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook">Facebook</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker ships Hadoop to the cloud]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/07/25/cloudbreak-technology/"/>
    <updated>2014-07-25T12:56:39+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/07/25/cloudbreak-technology</id>
    <content type="html"><![CDATA[<p>A week ago we have <a href="http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/">announced</a> and open sourced <a href="https://cloudbreak.sequenceiq.com/">Cloudbreak</a>, the first Docker based Hadoop as a Service API. In this post we&rsquo;d like to introduce you into the technical details and the building blocks of the architecture.
Cloudbreak is built on the foundation of cloud providers APIs, Apache Ambari, Docker containers, Serf and dnsmasq. It is a cloud agnostic solution &ndash; as all the Hadoop services and components are running inside Docker containers &ndash; and these containers are shipped across different cloud providers.</p>

<p>Cloudbreak product documentation: <a href="http://sequenceiq.com/cloudbreak">http://sequenceiq.com/cloudbreak</a></p>

<p>Cloudbreak API documentation: <a href="http://docs.cloudbreak.apiary.io/">http://docs.cloudbreak.apiary.io/</a></p>

<h2>How it works</h2>

<p>From Docker containers point of view we have two kind of containers &ndash; based on their Ambari role &ndash; server and agent. There is one Docker container running the Ambari server, and there are many Docker containers running the Ambari agents. The used Docker image is always the same: <code>sequenceiq/ambari</code> and
the Ambari role is decided based on the <code>$AMBARI_ROLE</code> variable.</p>

<p>For example on Amazon EC2 this is how we start the containers:</p>

<p><code>bash
docker run -d -p &lt;LIST of ports&gt; -e SERF_JOIN_IP=$SERF_JOIN_IP --dns 127.0.0.1 --name ${NODE_PREFIX}${INSTANCE_IDX} -h ${NODE_PREFIX}${INSTANCE_IDX}.${MYDOMAIN} --entrypoint /usr/local/serf/bin/start-serf-agent.sh  $IMAGE $AMBARI_ROLE
</code></p>

<p>As we are starting up the instances and the Docker containers on the host, we&rsquo;d like them to join each other and be able to communicate &ndash; though we don&rsquo;t know the IP addresses beforehand. This can be challanging on cloud environments &ndash; where your IP address and DNS name is dynamically allocated &ndash; however you don&rsquo;t want to collect these imformations beforehand launching the Docker containers.
For that we use Serf &ndash; and pass along the IP address <code>SERF_JOIN_IP=$SERF_JOIN_IP</code> of the first container. Using a gossip protocol Serf will automatically discover each other, set the DNS names, and configure the routing between the nodes.
Serf reconfigures the DNS server <code>dnsmasq</code> running inside the container, and keeps it up to date with the joining or leaving nodes information.
As you can see at startup we always pass a <code>--dns 127.0.0.1</code> dns server for the container to use.</p>

<p>As you see there is no cloud specific code at the Docker containers level, the same technology can be used on bare metal as well.
Check our previous blog posts about a <a href="http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">multi node Hadoop cluster on any host</a>.</p>

<p>Obliviously there is some configuration on the host as well &ndash; for that and to handle early initialization of a cloud instance we use <a href="https://help.ubuntu.com/community/CloudInit">CloudInit</a>. We will write a blog post about these for every cloud provider we support.</p>

<p>For additional information you can check our slides from the <a href="http://www.slideshare.net/JanosMatyas/docker-based-hadoop-provisioning">Hadoop Summit 2014</a>.</p>

<p>Once Ambari is started it will install the selected components based on the passed Hadoop blueprint &ndash; and start the desired services.</p>

<!-- more -->


<h2>Used Technologies</h2>

<h3>Apache Ambari</h3>

<p>The Apache Ambari project is aimed at making Hadoop management simpler by developing software for provisioning, managing, and monitoring Apache Hadoop clusters. Ambari provides an intuitive, easy-to-use Hadoop management web UI backed by its RESTful APIs.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/cloudbreak/master/docs/images/ambari-overview.png" alt="" /></p>

<p>Ambari enables System Administrators to:</p>

<ol>
<li>Provision a Hadoop Cluster</li>
<li>provides a step-by-step wizard for installing Hadoop services across any number of hosts.</li>
<li><p>handles configuration of Hadoop services for the cluster.</p></li>
<li><p>Manage a Hadoop Cluster</p></li>
<li><p>provides central management for starting, stopping, and reconfiguring Hadoop services across the entire cluster.</p></li>
<li><p>Monitor a Hadoop Cluster</p></li>
<li>provides a dashboard for monitoring health and status of the Hadoop cluster.</li>
<li>leverages Ganglia for metrics collection.</li>
<li>leverages Nagios for system alerting and will send emails when your attention is needed (e.g. a node goes down, remaining disk space is low, etc).</li>
</ol>


<p>Ambari enables to integrate Hadoop provisioning, management and monitoring capabilities into applications with the Ambari REST APIs.
Ambari Blueprints are a declarative definition of a cluster. With a Blueprint, you can specify a Stack, the Component layout and the Configurations to materialize a Hadoop cluster instance (via a REST API) without having to use the Ambari Cluster Install Wizard.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/cloudbreak/master/docs/images/ambari-create-cluster.png" alt="" /></p>

<h3>Docker</h3>

<p>Docker is an open platform for developers and sysadmins to build, ship, and run distributed applications. Consisting of Docker Engine, a portable, lightweight runtime and packaging tool, and Docker Hub, a cloud service for sharing applications and automating workflows, Docker enables apps to be quickly assembled from components and eliminates the friction between development, QA, and production environments. As a result, IT can ship faster and run the same app, unchanged, on laptops, data center VMs, and any cloud.</p>

<p>The main features of Docker are:</p>

<ol>
<li>Lightweight, portable</li>
<li>Build once, run anywhere</li>
<li>VM &ndash; without the overhead of a VM</li>
<li>Each virtualized application includes not only the application and the necessary binaries and libraries, but also an entire guest operating system</li>
<li><p>The Docker Engine container comprises just the application and its dependencies. It runs as an isolated process in userspace on the host operating system, sharing the kernel with other containers.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/cloudbreak/master/docs/images/vm.png" alt="" /></p></li>
<li><p>Containers are isolated</p></li>
<li>It can be automated and scripted</li>
</ol>


<h3>Serf</h3>

<p>Serf is a tool for cluster membership, failure detection, and orchestration that is decentralized, fault-tolerant and highly available. Serf runs on every major platform: Linux, Mac OS X, and Windows. It is extremely lightweight.
Serf uses an efficient gossip protocol to solve three major problems:</p>

<ul>
<li><p>Membership: Serf maintains cluster membership lists and is able to execute custom handler scripts when that membership changes. For example, Serf can maintain the list of Hadoop servers of a cluster and notify the members when nodes come online or go offline.</p></li>
<li><p>Failure detection and recovery: Serf automatically detects failed nodes within seconds, notifies the rest of the cluster, and executes handler scripts allowing you to handle these events. Serf will attempt to recover failed nodes by reconnecting to them periodically.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/cloudbreak/master/docs/images/serf-gossip.png" alt="" /></p></li>
<li><p>Custom event propagation: Serf can broadcast custom events and queries to the cluster. These can be used to trigger deploys, propagate configuration, etc. Events are simple fire-and-forget broadcast, and Serf makes a best effort to deliver messages in the face of offline nodes or network partitions. Queries provide a simple realtime request/response mechanism.</p>

<p><img src="https://raw.githubusercontent.com/sequenceiq/cloudbreak/master/docs/images/serf-event.png" alt="" /></p></li>
</ul>


<p>For updates follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cloudbreak - the Hadoop as a Service API]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/"/>
    <updated>2014-07-18T16:37:37+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak</id>
    <content type="html"><![CDATA[<p><em>Cloudbreak is a powerful left surf that breaks over a coral reef, a mile off southwest the island of Tavarua, Fiji.</em></p>

<p><em>Cloudbreak is a cloud agnostic Hadoop as a Service API. Abstracts the provisioning and ease management and monitoring of on-demand clusters.</em></p>

<p>Today is a big day for us and the Hadoop community &ndash; we are announcing the first <code>public beta</code> version of our open source and cloud agnostic <strong>Hadoop as a Service API</strong>.</p>

<p>During our daily work with large Hadoop clusters in the cloud, <code>dockerized</code> environments and bare metal we were doing the same things over and over again. Although we are automating and <code>dockerizing</code> always everything, we felt that something is missing &ndash; an open source, cloud agnostic Hadoop as a Service API. Welcome <a href="https://cloudbreak.sequenceiq.com">Cloudbreak</a> &ndash; you are one POST away from your on-demand Hadoop cluster on your favorite cloud provider.</p>

<p>When we have started to work on Cloudbreak &ndash; first of all to solve our internal needs at SequenceIQ &ndash; we have set the following criteria:</p>

<ul>
<li>Use open source software and be <strong>100% open source</strong> under Apache 2 license</li>
<li>Have the ability to quickly launch arbitrary sized Hadoop clusters</li>
<li>Be cloud provider agnostic and create an SDK which allows to quickly add new providers</li>
<li>No more glue code, repeating the same things over and over again</li>
<li>Have a REST API and a CLI in order to be able to automate the whole process</li>
<li>Create an easy to use and responsive UI</li>
<li>Support different Hadoop services and configurations in a declarative way</li>
<li>Elastic and flexible, with the ability to resize running clusters</li>
<li>Secure</li>
</ul>


<!-- more -->


<h2>Docker in the cloud</h2>

<p>At <a href="http://sequenceiq.com/">SequenceIQ</a> we are running all our core applications and processes in Docker containers &ndash; and that is true for Hadoop and all of the services as well. During the last few months we have <a href="http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">blogged</a> and open sourced all of the <a href="https://hub.docker.com/u/sequenceiq/">building blocks</a> of our <code>dockerized</code> systems and <strong>Cloudbreak</strong> is built on the foundation of these and reusing the same technologies we have released before. While Cloudbreak&rsquo;s primary role is to launch on-demand Hadoop clusters in the cloud, the underlying technology actually does more. It can launch on-demand Hadoop clusters in any environment which supports Docker &ndash; in a dynamic way. There is no predefined configuration needed as all the setup, orchestration, networking and cluster membership is done dynamically.</p>

<ul>
<li><a href="https://hub.docker.com/u/sequenceiq/">Docker containers</a> &ndash; all the Hadoop services are installed and running inside Docker containers, and these containers are <code>shipped</code>  between different cloud vendors, keeping Cloudbreak cloud agnostic</li>
<li><a href="https://github.com/sequenceiq/ambari-rest-client">Apache Ambari</a> &ndash; to declaratively define a Hadoop cluster</li>
<li><a href="https://github.com/sequenceiq/docker-serf">Serf</a> &ndash; for cluster membership, failure detection, and orchestration that is decentralized, fault-tolerant and highly available for dynamic clusters</li>
<li><a href="https://github.com/sequenceiq/docker-dnsmasq">dnsmasq</a> &ndash; to provide resolvable fully qualified domain names between dynamically created Docker containers.</li>
</ul>


<p>The project was presented at the <strong>Hadoop Summit 2014,</strong> in San Jose &ndash; you can get the slides from <a href="http://www.slideshare.net/JanosMatyas/docker-based-hadoop-provisioning">here</a>.</p>

<p>While there is an extensive list of articles explaining the benefits of using Docker, we would like to highlight our motivations in a few bullet points.</p>

<ul>
<li>Write once, run anywhere &ndash; our solution uses the same Docker containers on different cloud providers, <code>dockerized</code>  environments or bare metal, no difference at all</li>
<li>Reproducible, testable environment &ndash; we are recreating complete config environments in seconds, and being able to work with the same containers on our laptop, QA and production/cloud environments</li>
<li>Isolation &ndash; each container is separated and runs in its own isolated sandbox</li>
<li>Versioning &ndash; we are able to easily version and modify containers, and ship only the changed bits saving bandwidth; essential for large clusters deployed in the cloud</li>
<li>Central repository &ndash; you can build an entire cluster from a trusted and centralised container repository, the Docker Registry/Hub</li>
<li>Smart resource allocation &ndash; containers can be <code>shipped</code> anywhere and resources can be allotted</li>
</ul>


<h2>Cloudbreak &ndash; the project</h2>

<h3>Cloudbreak UI</h3>

<p>The easiest way to start your own Hadoop cluster in your favorite cloud provider is to use our hosted solution. We host, maintain and support <a href="https://cloudbreak.sequenceiq.com/">Cloudbreak</a> for you. Cloudbreak UI is a secure and intuitive way to launch on-demand Hadoop clusters with a few mouse clicks. Please note that Cloudbreak is launching Hadoop clusters on the user&rsquo;s behalf &ndash; on different cloud providers. We do not store your cloud provider account details (such as username, password, keys, private SSL certificates, etc), but work around the concept that Identity and Access Management is fully controlled by you &ndash; the end user.</p>

<h3>Cloudbreak API</h3>

<p>Cloudbreak is a RESTful Hadoop as a Service API. The easiest way to use the API is by using our hosted <a href="http://docs.cloudbreak.apiary.io/">Cloudbreak API</a>.</p>

<p>We have also give you the option to host Cloudbreak within your organization. Once it is deployed in your favourite servlet container exposes a REST API allowing to span up Hadoop clusters of arbitrary sizes on your selected cloud provider. With Cloudbreak you are one POST away from your on-demand Hadoop cluster. You can get the code from our <a href="https://github.com/sequenceiq/cloudbreak">GitHub repository</a>. For further documentation please follow up with the <a href="http://sequenceiq.com/cloudbreak/">general</a> and <a href="http://docs.cloudbreak.apiary.io/">API</a> documentation, or subscribe to one of our social channels in order to receive notifications about further blog posts and releases.</p>

<h3>Cloudbreak REST client</h3>

<p>In order to ease your work with the REST API and embed in your codebase we have created (and also extensively use) a Groovy REST client. The code is available at our <a href="https://github.com/sequenceiq/cloudbreak-rest-client">GitHub</a> repository.</p>

<h3>Cloudbreak CLI</h3>

<p>As we automate everything and we are a very DevOps focused company we are always trying to create easy ways to interact with our systems and API’s. In case of Cloudbreak we have created and released a <a href="https://github.com/sequenceiq/cloudbreak-shell">command line shell</a>, the Cloudbreak CLI. The CLI allows you to use all the REST calls, and it has a large number of easing commands. Interactive help and completion is available.</p>

<h3>Cloudbreak documentation</h3>

<p>We have created two types of documentation. The <a href="http://sequenceiq.com/cloudbreak/">Cloudbreak Product</a> documentation contains an overview, installation, architectural and technical content, whereas the <a href="http://docs.cloudbreak.apiary.io/">Cloudbreak API</a> explains the REST API with examples and a mock server to test your integration.</p>

<h2>Supported Hadoop services</h2>

<p>At high level the supported list of components can be grouped into two main categories: Master and Slave &ndash; and bundling them together form a Hadoop Service. <a href="https://cloudbreak.sequenceiq.com/">Cloudbreak</a> supports the following Hadoop services.</p>

<p><code>
| Services    | Components                                                              |
| ----------- | ------------------------------------------------------------------------|
| HDFS        | DATANODE, HDFS_CLIENT, JOURNALNODE, NAMENODE, SECONDARY_NAMENODE, ZKFC  |
| YARN        | APP_TIMELINE_SERVER, NODEMANAGER, RESOURCEMANAGER, YARN_CLIENT          |
| MAPREDUCE2  | HISTORYSERVER, MAPREDUCE2_CLIENT                                        |
| GANGLIA     | GANGLIA_MONITOR, GANGLIA_SERVER                                         |
| HBASE       | HBASE_CLIENT, HBASE_MASTER, HBASE_REGIONSERVER                          |
| HIVE        | HIVE_CLIENT, HIVE_METASTORE, HIVE_SERVER, MYSQL_SERVER                  |
| HCATALOG    | HCAT                                                                    |
| WEBHCAT     | WEBHCAT_SERVER                                                          |
| NAGIOS      | NAGIOS_SERVER                                                           |
| OOZIE       | OOZIE_CLIENT, OOZIE_SERVER                                              |
| PIG         | PIG                                                                     |
| SQOOP       | SQOOP                                                                   |
| STORM       | DRPC_SERVER, NIMBUS, STORM_REST_API, STORM_UI_SERVER, SUPERVISOR        |
| TEZ         | TEZ_CLIENT                                                              |
| FALCON      | FALCON_CLIENT, FALCON_SERVER                                            |
| ZOOKEEPER   | ZOOKEEPER_CLIENT, ZOOKEEPER_SERVER                                      |
</code></p>

<p>Please note that you can always build your own custom stack beyond these services, using Ambari&rsquo;s custom stack definitions.</p>

<h2>What’s next?</h2>

<p>We will follow up with a few posts to drive you through the technology, API and insights and make it easier for you to learn, understand and use Hadoop in the cloud.</p>

<p>In the meantime we suggest you to go through the <a href="http://sequenceiq.com/cloudbreak/">documentation</a>, try <a href="http://cloudbreak.sequenceiq.com/">Cloudbreak</a> and let us know how it works for you.</p>

<p>Please note that <a href="http://cloudbreak.sequenceiq.com/">Cloudbreak</a> is under development, in public beta &ndash; while we consider the codebase stable for deployments (and use it daily), please let us know if you face any problems through <a href="https://github.com/sequenceiq/cloudbreak">GitHub</a> issues. Also we  welcome your open source contribution &ndash; let it be a bug fix or a new cloud provider <a href="http://sequenceiq.com/cloudbreak/#add-new-cloud-providers">implementation</a>.</p>

<p>Finally, your opinion is important to us &ndash; if you’d like to see your <strong>favourite cloud provider</strong> among the existing ones, please fill this <a href="https://docs.google.com/forms/d/129RVh6VfjRsuuHOcS3VPbFYTdM2SEjANDsGCR5Pul0I/viewform">questionnaire</a>. Make your voice heard!</p>

<p>For updates follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>
]]></content>
  </entry>
  
</feed>
