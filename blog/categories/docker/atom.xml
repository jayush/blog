<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | SequenceIQ Blog]]></title>
  <link href="http://blog.sequenceiq.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://blog.sequenceiq.com/"/>
  <updated>2014-09-24T14:18:56+00:00</updated>
  <id>http://blog.sequenceiq.com/</id>
  <author>
    <name><![CDATA[SequenceIQ]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Apache Tez cluster on Docker]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/09/19/apache-tez-cluster/"/>
    <updated>2014-09-19T07:42:58+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/09/19/apache-tez-cluster</id>
    <content type="html"><![CDATA[<p>This week the <a href="http://tez.apache.org/">Apache Tez</a> community announced the release of the 0.5 version of the project. At <a href="http://sequenceiq.com/">SequenceIQ</a> first time we came across Tez was in 2013 &ndash; after <a href="http://hortonworks.com/">Hortonworks</a> launched the <code>Stinger Initiative</code>. Though we were not using Hive (that might change soon) we have quickly realized the <code>other</code> capabilities of Tez &ndash; the expressive data flow API, data movement patterns, dynamic graph reconfiguration, etc &ndash; to name a few.</p>

<p>We quickly became <code>fans</code> of Tez &ndash; and have started to run internal PoC projects, rewrite ML algorithms and legacy MR2 code to run/leverage Tez. The new release comes with a stable developer API and a proven stability track, and this has triggered a <code>major</code> re-architecture/refactoring project at SequenceIQ. While I don’t want to enter into deep details, we are building a Platform as a Service API &ndash; with the first stages of the project already released, open sourced and in public beta:</p>

<p><a href="http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/">Cloudbreak</a> &ndash; our Docker based cloud agnostic Hadoop as a Service API (AWS, Azure, Google Cloud, DigitalOcean);
<a href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/">Periscope</a> &ndash; an SLA policy based autoscaling API for Hadoop YARN</p>

<p>One of the unreleased component is a project called <a href="http://docs.banzai.apiary.io/">Banzai Pipeline</a> &ndash; a big data pipeline API (with 50+ pre-built data and job pipes), running on <strong>MR2, Tez and Spark</strong>.</p>

<p>With all these said, we have put together a <code>Tez Ready</code> Docker based Hadoop cluster to share our excitement and allow you to quickly start and get familiar with the nice features of the Tez API. The cluster is built on our widely used Apache Ambari Docker <a href="http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">container</a>, with some additional features. The containers are <code>service discovery</code> aware. You don’t need to setup anything beforehand, configure IP addresses or DNS names &ndash; the only thing you will need to do is just specify the number of nodes desired in your cluster, and you are ready to go. If you are interested on the underlying architecture (using Docker, Serf and dnsmasq) you can check my slides/presentation from the <a href="http://www.slideshare.net/JanosMatyas/docker-based-hadoop-provisioning">Hadoop Summit</a>.</p>

<p>I&rsquo;d like to highlight one important feature of Tez &ndash; us being crazy about automation/DevOps &ndash; the simplicity and the capability of running multiple versions of Tez on the same YARN cluster. We are contributors to many Apache projects (Hadoop, YARN, Ambari, etc) and since we have started to use Tez we consider to contribute there as well (at the end of the day will be a core part of our platform). Adding new features, changing code or fixing bugs always introduce undesired <code>features</code> &ndash; nevertheless, the Tez binaries built by different colleagues can be tested at scale, using the same cluster without affecting each others work. Check Gopal V&rsquo;s good <a href="http://bit.ly/tez-devops">introduction</a> about Tez and DevOps.</p>

<h2>Apache Tez cluster on Docker</h2>

<p>The container’s code is available on our <a href="https://github.com/sequenceiq/docker-ambari/tree/1.7.0-ea-tez">GitHub</a> repository.</p>

<h3>Pull the image from the Docker Repository</h3>

<p>We suggest to always pull the container from the official Docker repository &ndash; as this is always maintained and supported by us.</p>

<p><code>
docker pull sequenceiq/ambari:1.7.0-ea-tez
</code></p>

<!-- more -->


<h3>Building the image</h3>

<p>Alternatively you can always build your own container based on our Dockerfile.</p>

<p><code>
docker build --rm -t sequenceiq/ambari:1.7.0-ea-tez ambari-server/
</code></p>

<h2>Running the cluster</h2>

<p>We have put together a few shell functions to simplify your work, so before you start make sure you get the following <code>ambari-functions</code> <a href="https://github.com/sequenceiq/docker-ambari/blob/1.7.0-ea-tez/ambari-functions">file</a>.</p>

<p><code>
curl -Lo .amb j.mp/docker-ambari-tez &amp;&amp; . .amb
</code></p>

<h3>Create your Apache Tez cluster</h3>

<p>You are almost there. The only thing you will need to do is to specify the number of nodes you need in your cluster. We will launch the containers, they will dynamically join the cluster and apply the Tez specific configurations.</p>

<p><code>
amb-deploy-cluster 4
</code></p>

<p>Once the cluster is started you can <a href="http://blog.sequenceiq.com/blog/2014/07/05/docker-debug-with-nsenter-on-boot2docker/">enter</a> in the container and submit your custom Tez application or use one of the stock Tez examples.</p>

<p>Check back next week, as we are releasing <code>real world</code> examples running on three different big data fabrics: Tez, MR2 and Spark.</p>

<p>Should you have any questions let us know through our social channels using <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cloudbreak new provider implementation - Part I: Build your custom image]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/09/18/custom-image-on-gcc/"/>
    <updated>2014-09-18T07:42:58+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/09/18/custom-image-on-gcc</id>
    <content type="html"><![CDATA[<p>Not so long ago we have released <a href="http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/">Cloudbreak</a> &ndash; the cloud agnostic, open source and Docker based Hadoop as a Service API (with support for <a href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/">autoscaling</a> Hadoop clusters). As we have <code>dockerized</code> the whole Hadoop ecosystem, we are shipping the containers to different cloud providers, such as Amazon AWS, Microsoft Azure and Google Cloud Compute. Also Cloudbreak has an <a href="http://sequenceiq.com/cloudbreak/#add-new-cloud-providers">SDK</a> which allows you to quickly add your favorite cloud provider. In this post (series) we’d like to guide you trough the process, and show you how to create a custom image &ndash; on Google Cloud. We have chose Google Cloud as this is the least documented and has the smallest amount on default images (there are thousand for Amazon, and hundreds for Azure). Nevertheless on all cloud provider usually you’d like to have a custom image with your preferred OS, configuration and potentially installed applications.</p>

<!-- more -->


<h3>Why do we need custom images on every cloud?</h3>

<p>All the above are true for us as well &ndash; with some simplifications. We use Docker to run every process/application &ndash; for the benefits we have covered in other posts many times &ndash; and apart from Docker, our (or the customer’s) preferred OS and a few other helper/debugger things (such as <a href="https://registry.hub.docker.com/u/jpetazzo/nsenter/">nsenter</a>)
we are almost fine. We have made some PAM related fixes/contributions for Docker &ndash; and until they are not in the upstream we have built/derive from our base layer/containers &ndash; so with this and the actual containers included this is pretty much how a cloud base image looks like for us.</p>

<p>As usual we always automate everything &ndash; building custom cloud base images is part of the automation and our CI/CD process as well. For that we use <a href="http://www.ansible.com/home">Ansible</a> as the preferred IT automation tool. So the first step is to define your own <a href="http://docs.ansible.com/playbooks.html">playbook</a> to install everything on the virtual machine.</p>

<p>A simple playbook looks like this:</p>

<p>```
  &ndash; name: Install Docker</p>

<pre><code>shell: curl -sL https://get.docker.io/ | sh
when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'
</code></pre>

<ul>
<li><p>name: Pull sequenceiq/ambari image
shell: docker pull sequenceiq/ambari:pam-fix</p></li>
<li><p>name: Pull jpetazzo/nsenter image
shell: docker pull jpetazzo/nsenter</p></li>
<li><p>name: Install bridge-utils
apt: name=bridge-utils state=latest
when: ansible_distribution == &lsquo;Debian&rsquo; or ansible_distribution == &lsquo;Ubuntu&rsquo;</p></li>
<li><p>name: install jq
shell: curl -o /usr/bin/jq <a href="http://stedolan.github.io/jq/download/linux64/jq">http://stedolan.github.io/jq/download/linux64/jq</a> &amp;&amp; chmod +x /usr/bin/jq</p></li>
</ul>


<p>```</p>

<p>Using Google cloud you have 2 choices:</p>

<ol>
<li> Create snapshots starting from a default image</li>
<li> Create a custom image</li>
</ol>


<h3>Image creation using snapshots</h3>

<p>We are using Debian as the host OS on Google Cloud, and have created a virtual machine using the default <a href="https://developers.google.com/compute/docs/operating-systems#backported_debian_7_wheezy">Debian</a> image. First thing first, you need to create a persistent disk:</p>

<p><code>
gcloud compute disks create temporary-disk --zone ZONE
</code></p>

<p>Then create a virtual machine with the temporary-disk:</p>

<p><code>
gcloud compute instances create example-instance \
  --scopes storage-rw --image IMAGE \
  --disk name=temporary-disk device-name=temporary-disk --zone ZONE
</code></p>

<p>And attach the disk to the google cloud instance:</p>

<p><code>
gcloud compute instances attach-disk example-instance
  --disk temporary-disk --device-name temporary-disk --zone ZONE
</code></p>

<p>When this is finished then you can <code>shh</code> to the <code>sample-instance</code>. You can now check your mounted volumes with this command:</p>

<p><code>
ls -l /dev/disk/by-id/google-*
</code></p>

<p>Now you need to create a folder which will contain your custom built image:</p>

<p><code>
sudo mkdir /mnt/tmp
</code></p>

<p>You have to format your partition before the image creation:</p>

<p><code>
sudo /usr/share/google/safe_format_and_mount -m "mkfs.ext4 -F" /dev/sdb /mnt/tmp
</code></p>

<p>Now you can start building the image which will last about 10 minutes:</p>

<p><code>
sudo gcimagebundle -d /dev/sda -o /mnt/tmp/ --log_file=/tmp/imagecreation.log
</code></p>

<p>You have now an image in /tmp with a special hex number like <code>/tmp/HEX-NUMBER.image.tar.gz</code></p>

<p>Once you uploaded it to a Google bucket you are done, and ready to use it.</p>

<p><code>
gsutil cp /mnt/tmp/IMAGE_NAME.image.tar.gz gs://BUCKET_NAME
</code></p>

<h3>Create a custom image &ndash; using your favorite OS</h3>

<p><a href="http://www.ubuntu.com/download/server">Ubuntu server 14.04</a> is many’s preferred Linux distribution &ndash; unluckily there is no default image using Ubuntu as the OS in the Google Cloud](<a href="https://developers.google.com/compute/docs/operating-systems">https://developers.google.com/compute/docs/operating-systems</a>). Luckily this is not that complicated &ndash; the process below works with any other OS as well. In order to start you should have <a href="https://www.virtualbox.org/">Virtualbox</a> installed. Download an Ubuntu server from <a href="http://www.ubuntu.com/server">Ubuntu’s</a> web page.
Install in into the <a href="https://www.virtualbox.org/">Virtualbox</a> box, start it and <code>ssh</code> into. Once you are inside you will have to install the <a href="https://developers.google.com/cloud/sdk/">Google Cloud SDK</a>. This is needed for the custom image, as contains some extra feature like <code>google-startup-scripts</code>. Remember that Ubuntu (and in general a few cloud providers) support <code>cloud-init</code> scripts, and this is why we need the Google Cloud SDK &ndash; as we ship these images to the <code>cloud</code>.</p>

<p>After the installation add the following kernel options into the <code>/etc/default/grub</code>:</p>

<p>```</p>

<h1>to enable paravirtualization</h1>

<p>CONFIG_KVM_GUEST=y</p>

<h1>to enable the paravirtualized clock.</h1>

<p>CONFIG_KVM_CLOCK=y</p>

<h1>to enable paravirtualized PCI devices.</h1>

<p>CONFIG_VIRTIO_PCI=y</p>

<h1>to enable access to paravirtualized disks.</h1>

<p>CONFIG_SCSI_VIRTIO=y</p>

<h1>to enable access to the networking.</h1>

<p>CONFIG_VIRTIO_NET=y
```</p>

<p>Now you are ready to prepare an <code>official</code> image into a tar file, by selecting the virtual box image file on your disk and convert it.
You can convert your <code>vmdk</code> file into the supported raw type by using:</p>

<p><code>
qemu-img convert -f vmdk -O raw VMDK_FILE_NAME.vmdk disk.img
</code></p>

<p>The .img file name has to be <code>disk.img</code>. After you have converted the image, you have to make a tar file:</p>

<p><code>
tar -Szcf &lt;image-tar-name&gt;.tar.gz disk.raw
</code></p>

<p>Same as before, you have to upload in to a Google Cloud Bucket:</p>

<p><code>
gsutil cp &lt;image-tar-name&gt;.tar.gz gs://&lt;bucket-name&gt;
</code></p>

<p>Now you have an <code>official</code> image template but you have to create the image in Google Cloud:</p>

<p><code>
gcutil addimage my-ubuntu gs://&lt;bucket-name&gt;/ubuntu_image.tar.gz
</code></p>

<p>Once this is done you have created your custom built Google Cloud image, and you are ready to start cloud instances using it. Let us know how it works for you, and make sure you follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook.com/sequenceiq">Facebook</a> for updates.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apache Spark 1.1.0 on Docker]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/09/17/spark-1-1-0-docker/"/>
    <updated>2014-09-17T18:07:18+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/09/17/spark-1-1-0-docker</id>
    <content type="html"><![CDATA[<p>As you might be already familiar, we have <code>dockerized</code> most of the Hadoop ecosystem &ndash; we are running MR2, Spark, Storm, Hive, HBase, Pig, Oozie, Drill etc in Docker containers &ndash; on bare metal and in the cloud as well. For details you can check these older posts/resources:</p>

<table>
<thead>
<tr>
<th></th>
<th> Name                  </th>
<th> Description </th>
<th> Documentation </th>
<th> GitHub</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td> Apache Hadoop  </td>
<td> Pseudo distributed container </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/08/18/hadoop-2-5-0-docker/">http://blog.sequenceiq.com/blog/2014/08/18/hadoop-2-5-0-docker/</a> </td>
<td> <a href="https://github.com/sequenceiq/hadoop-docker">https://github.com/sequenceiq/hadoop-docker</a></td>
</tr>
<tr>
<td></td>
<td> Apache Ambari   </td>
<td> Multi node &ndash; full Hadoop stack, blueprint based </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/</a> </td>
<td> <a href="https://github.com/sequenceiq/docker-ambari">https://github.com/sequenceiq/docker-ambari</a></td>
</tr>
<tr>
<td></td>
<td> Cloudbreak         </td>
<td> Cloud agnostic Hadoop as a Service </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/">http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/</a> </td>
<td> <a href="https://github.com/sequenceiq/cloudbreak">https://github.com/sequenceiq/cloudbreak</a></td>
</tr>
<tr>
<td></td>
<td> Periscope          </td>
<td> SLA policy based autoscaling for Hadoop clusters </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/">http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/</a> </td>
<td> <a href="https://github.com/sequenceiq/periscope">https://github.com/sequenceiq/periscope</a> </td>
</tr>
</tbody>
</table>


<p>In this current post we’d like to help you to start with the <code>latest - 1.1.0</code> Spark release in minutes &ndash; using Docker. Docker and Spark are two technologies which are very <code>hyped</code> these days. At <a href="http://sequenceiq.com/">SequenceIQ</a> we use both quite a lot, thus we put together a Docker container and sharing it with the community.</p>

<p>The container’s code is available in our <a href="https://github.com/sequenceiq/docker-spark/blob/v1.1onHadoop-2.5.1/README.md">GitHub</a> repository.</p>

<h3>Pull the image from Docker Repository</h3>

<p>We suggest to always pull the container from the official Docker repository &ndash; as this is always maintained and supported by us.</p>

<p><code>
docker pull sequenceiq/spark:1.1.0
</code></p>

<!-- more -->


<h2>Building the image</h2>

<p>Alternatively you can always build your own container based on our Dockerfile.</p>

<p><code>
docker build --rm -t sequenceiq/spark:1.1.0 .
</code></p>

<h2>Running the image</h2>

<p>Once you have pulled or built the container, you are ready to start with Spark.</p>

<p><code>
docker run -i -t -h sandbox sequenceiq/spark /etc/bootstrap.sh -bash
</code></p>

<h3>Testing</h3>

<p>In order to check whether everything is OK, you can run one of the stock examples, coming with Spark. Check our previous blog posts and examples about Spark <a href="http://blog.sequenceiq.com/blog/2014/07/31/spark-mllib/">here</a> and <a href="http://blog.sequenceiq.com/blog/2014/08/22/spark-submit-in-java/">here</a>.</p>

<p>```
cd /usr/local/spark</p>

<h1>run the spark shell</h1>

<p>./bin/spark-shell &mdash;master yarn-client &mdash;driver-memory 1g &mdash;executor-memory 1g &mdash;executor-cores 1</p>

<h1>execute the the following command which should return 1000</h1>

<p>scala> sc.parallelize(1 to 1000).count()
```</p>

<p>There are two deploy modes that can be used to launch Spark applications on YARN. In yarn-cluster mode, the Spark driver runs inside an application master process which is managed by YARN on the cluster, and the client can go away after initiating the application. In yarn-client mode, the driver runs in the client process, and the application master is only used for requesting resources from YARN.</p>

<p>Estimating Pi (yarn-cluster mode):</p>

<p>```
cd /usr/local/spark</p>

<h1>execute the the following command which should write the &ldquo;Pi is roughly 3.1418&rdquo; into the logs</h1>

<p>./bin/spark-submit &mdash;class org.apache.spark.examples.SparkPi &mdash;master yarn-cluster &mdash;driver-memory 1g &mdash;executor-memory 1g &mdash;executor-cores 1 examples/target/scala-2.10/spark-examples_2.10-1.0.1.jar
```</p>

<p>Estimating Pi (yarn-client mode):</p>

<p>```
cd /usr/local/spark</p>

<h1>execute the the following command which should print the &ldquo;Pi is roughly 3.1418&rdquo; to the screen</h1>

<p>./bin/spark-submit &mdash;class org.apache.spark.examples.SparkPi &mdash;master yarn-client &mdash;driver-memory 1g &mdash;executor-memory 1g &mdash;executor-cores 1 examples/target/scala-2.10/spark-examples_2.10-1.0.1.jar
```</p>

<p>Should you have any questions let us know through our social channels using <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apache Hadoop 2.5.1 on Docker]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/09/15/hadoop-2-5-1-docker/"/>
    <updated>2014-09-15T18:07:18+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/09/15/hadoop-2-5-1-docker</id>
    <content type="html"><![CDATA[<p>Following the release cycle of Hadoop, today we are releasing a new <code>2.5.1</code> version of our <a href="https://registry.hub.docker.com/u/sequenceiq/hadoop-docker/">Hadoop Docker container</a>. Up until today the container was only <code>CentOS</code> based, but during the last few months we got lots of requests to release a Hadoop container on <code>Ubuntu</code> as well. From now on we will have both released, supported and published to the official Docker repository. Enjoy.</p>

<h2>Centos</h2>

<h3>Build the image</h3>

<p>In case you&rsquo;d like to try directly from the <a href="https://github.com/sequenceiq/hadoop-docker/tree/2.5.1">Dockerfile</a> you can build the image as:</p>

<p><code>
docker build  -t sequenceiq/hadoop-docker:2.5.1 .
</code></p>

<!-- more -->


<h3>Pull the image</h3>

<p>As it is also released as an official Docker image from Docker&rsquo;s automated build repository &ndash; you can always pull or refer the image when launching containers.</p>

<p><code>
docker pull sequenceiq/hadoop-docker:2.5.1
</code></p>

<h3>Start a container</h3>

<p>In order to use the Docker image you have just build or pulled use:</p>

<p><code>
docker run -i -t sequenceiq/hadoop-docker:2.5.1 /etc/bootstrap.sh -bash
</code></p>

<h2>Ubuntu</h2>

<h3>Build the image</h3>

<p>In case you&rsquo;d like to try directly from the <a href="https://github.com/sequenceiq/docker-hadoop-ubuntu/tree/2.5.1">Dockerfile</a> you can build the image as:</p>

<p><code>
docker build  -t sequenceiq/hadoop-ubuntu:2.5.1 .
</code></p>

<!-- more -->


<h3>Pull the image</h3>

<p>As it is also released as an official Docker image from Docker&rsquo;s automated build repository &ndash; you can always pull or refer the image when launching containers.</p>

<p><code>
docker pull sequenceiq/hadoop-ubuntu:2.5.1
</code></p>

<h3>Start a container</h3>

<p>In order to use the Docker image you have just build or pulled use:</p>

<p><code>
docker run -i -t sequenceiq/hadoop-ubuntu:2.5.1 /etc/bootstrap.sh -bash
</code></p>

<h2>Testing</h2>

<p>You can run one of the stock examples:</p>

<p>```
cd $HADOOP_PREFIX</p>

<h1>run the mapreduce</h1>

<p>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.1.jar grep input output &lsquo;dfs[a-z.]+&rsquo;</p>

<h1>check the output</h1>

<p>bin/hdfs dfs -cat output/*
```</p>

<h2>Hadoop native libraries, build, Bintray, etc</h2>

<p>The Hadoop build process is no easy task &ndash; requires lots of libraries and their right version, protobuf, etc and takes some time &ndash; we have simplified all these, made the build and released a 64b version of Hadoop nativelibs on our <a href="https://bintray.com/sequenceiq/sequenceiq-bin/hadoop-native-64bit/2.5.0/view/files">Bintray repo</a>. Enjoy.</p>

<p>Should you have any questions let us know through our social channels as <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apache Drill on Docker - query as a service ]]></title>
    <link href="http://blog.sequenceiq.com/blog/2014/09/11/apache-drill-docker/"/>
    <updated>2014-09-11T16:00:00+00:00</updated>
    <id>http://blog.sequenceiq.com/blog/2014/09/11/apache-drill-docker</id>
    <content type="html"><![CDATA[<p>As you might be already familiar, we have <code>dockerized</code> most of the Hadoop ecosystem &ndash; we are running MR2, Spark, Storm, Hive, HBase, Pig, Oozie, etc in Docker containers &ndash; on bare metal and in the cloud as well. We have started to use (and contribute) to Docker quite a while ago, and beside the <code>mainstream</code> benefits of containers one feature was extremely appealing to us &ndash; <strong>the SOA way of DevOps</strong>. Before I go on and explore what we mean under this allow me to collect a few links for your reference (all open sourced under an <strong>Apache 2 license</strong>), in case you plan to use Hadoop in Docker containers.</p>

<table>
<thead>
<tr>
<th></th>
<th> Name                  </th>
<th> Description </th>
<th> Documentation </th>
<th> GitHub</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td> Apache Hadoop  </td>
<td> Pseudo dist. container </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/08/18/hadoop-2-5-0-docker/">http://blog.sequenceiq.com/blog/2014/08/18/hadoop-2-5-0-docker/</a> </td>
<td> <a href="https://github.com/sequenceiq/hadoop-docker">https://github.com/sequenceiq/hadoop-docker</a></td>
</tr>
<tr>
<td></td>
<td> Apache Ambari   </td>
<td> Multi node &ndash; full Hadoop stack, blueprint based </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/">http://blog.sequenceiq.com/blog/2014/06/19/multinode-hadoop-cluster-on-docker/</a> </td>
<td> <a href="https://github.com/sequenceiq/docker-ambari">https://github.com/sequenceiq/docker-ambari</a></td>
</tr>
<tr>
<td></td>
<td> Cloudbreak         </td>
<td> Cloud agnostic Hadoop as a Service </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/">http://blog.sequenceiq.com/blog/2014/07/18/announcing-cloudbreak/</a> </td>
<td> <a href="https://github.com/sequenceiq/cloudbreak">https://github.com/sequenceiq/cloudbreak</a></td>
</tr>
<tr>
<td></td>
<td> Periscope          </td>
<td> SLA policy based autoscaling for Hadoop clusters </td>
<td> <a href="http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/">http://blog.sequenceiq.com/blog/2014/08/27/announcing-periscope/</a> </td>
<td> <a href="https://github.com/sequenceiq/periscope">https://github.com/sequenceiq/periscope</a> </td>
</tr>
</tbody>
</table>


<h2>Apache Drill at SequenceIQ</h2>

<p><a href="http://incubator.apache.org/drill/">Apache Drill</a> is an open source, low latency SQL query engine for Hadoop and NoSQL. It has many nice and interesting features, but one of the most interesting one (at least for us) is the <a href="https://cwiki.apache.org/confluence/display/DRILL/Storage+Plugin+Registration">storage plugin</a> and the tolerance/support for dynamic schemas. At <a href="http://sequenceiq.com/">SequenceIQ</a> the pre and post processed data ends up in different storage systems/layers. Obliviously we use HDFS, for low latency queries we use HBase and recently (with the emergence of Tez &ndash; which we consider the next big thing) we started to use Hive as well. Quite often there is a need to access the data from <code>legacy</code> systems &ndash; and more often we see <code>SQL</code> coming back in the picture. Just FYI, for SQL on HBase we are using <a href="http://phoenix.apache.org/">Apache Phoenix</a>, and of course we have released and open sourced a <a href="http://blog.sequenceiq.com/blog/2014/09/04/sql-on-hbase-with-apache-phoenix/">Docker container</a>.</p>

<p>As you see there are many storage systems use &ndash; and Drill helps us with aggregating these under one common <code>ANSI SQL syntax</code>. You can query data from HDFS, HBase, Hive, local or remote distributed file system &ndash; or write your own custom storage plugin.</p>

<!-- more -->


<h3>Lifecycle of a Drill query</h3>

<p>Let’s take a simple example (from the Drill samples), where we query a file, with a <code>WHERE</code> clause. Your statement is submitted in <code>Sqlline</code> &ndash; a very popular (used with our Phoenix container as well) Java interface which can talk to a JDBC driver. The <code>SELECT</code> statement is passed into <a href="http://optiq.incubator.apache.org/">Optiq</a>. Optiq is a library for query parsing and planning, and allows pluggable transformation rules. Optiq also has a cost-based query optimizer. At high level, based on the above the statements are converted into Drill <code>logical operators</code>, and form a Drill logical plan. This plan is then submitted into one <code>DrillBit service</code> &ndash; usually running on each datanode, to benefit on the data locality, during query execution. This logical plan is then transformed into a physical plan &ndash; a simple DAG  of physical operators &ndash; using a Drill’s <code>optimizer</code>. This physical plan is broken into a multi-level execution tree (hello MPP) that is executed by multiple DrillBits. The story goes on as there are statistics collected, endpoint affinities are checked (metadata based preferred endpoint selection) and the plan is broken in fragments, but at a high level this is the execution flow.
There are some interesting things going on under the hood which we can cover it one of the following posts &ndash; about writing our custom storage plugin.</p>

<h2>Apache Drill on Docker</h2>

<p>Now as you have a good overview about the capabilities of Drill, we’d like to expand on what we mean under <strong>SOA way of DevOps</strong>. Though Drill is a complex piece of software, essentially the provided service is extremely simple: <em>queries data</em>. We have created a <a href="https://registry.hub.docker.com/u/sequenceiq/drill/">Drill Docker</a> container and wrapped the <code>query</code> service inside. If you’d like to use Drill, the only thing you will have to do is to launch our Drill container &ndash; the <code>query service</code> is available <em>as a Service</em>. We have built the container in such a way that the data layer is separated from the <code>query service</code> &ndash; you can launch the container when and where you’d like to do, and attach the data using volumes. Once the data layer is attached, the only remaining thing is to let Drill know where to query &ndash; by either using one of the existing, or creating a new storage configuration.</p>

<h3>Pull the container</h3>

<p>The Drill container is available as a trusted build on Docker.io. You can get and start using it &ndash; the only prerequisite is to have Docker installed.</p>

<p><code>docker pull sequenceiq/drill</code></p>

<h3>Use the container</h3>

<p>Once the container is pulled you are ready to query your data by running:</p>

<p><code>docker run -it -v /data:/data sequenceiq/drill /etc/bootstrap.sh</code></p>

<p>Note that the <code>-v /data:/data</code> flag specifies that you are mounting your <code>/data</code> directory on the host into a <code>/data</code> directory inside the container. The files inside the directory will be available for Drill to query, by either using the default <code>dfs</code> storage plugin, or by a custom one. To check, or create a storage plugin or to access the Drill UI you should go to <code>http://CONTAINER_IP:8047</code>. You can find your container IP by using <code>docker inspect ID</code>.</p>

<p>In case you don&rsquo;t have any data, but would still like to explore Drill, start the contaier as:</p>

<p><code>docker run -it sequenceiq/drill /etc/bootstrap.sh</code></p>

<p>The sample data installed by default with Drill is available inside the container, thus you&rsquo;d be able to run all the Drill examples/tutorials.</p>

<h3>Drill Rest API</h3>

<p>Get Drillbit status: <code>http://localhost:8047/status</code>
Get all submitted queries: <code>http://localhost:8047/queries</code>
Get status of a given query:<code>http://localhost:8047/query/{QUERY_ID}</code></p>

<p>The next version of the container will be a fully distributed (based on our Hadoop container and Hazelcast) Apache Drill Docker container. Until then feel free to let us know how you <code>drill</code> and follow us on <a href="https://www.linkedin.com/company/sequenceiq/">LinkedIn</a>, <a href="https://twitter.com/sequenceiq">Twitter</a> or <a href="https://www.facebook.com/sequenceiq">Facebook</a>.</p>
]]></content>
  </entry>
  
</feed>
