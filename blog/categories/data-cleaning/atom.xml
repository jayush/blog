<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Data cleaning | SequenceIQ Blog]]></title>
  <link href="http://blog.sequenceiq.com//blog/categories/data-cleaning/atom.xml" rel="self"/>
  <link href="http://blog.sequenceiq.com//"/>
  <updated>2014-03-05T14:57:10+00:00</updated>
  <id>http://blog.sequenceiq.com//</id>
  <author>
    <name><![CDATA[SequenceIQ]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ETL - producing better quality data]]></title>
    <link href="http://blog.sequenceiq.com//blog/2014/02/28/etl-and-data-quality/"/>
    <updated>2014-02-28T08:12:44+00:00</updated>
    <id>http://blog.sequenceiq.com//blog/2014/02/28/etl-and-data-quality</id>
    <content type="html"><![CDATA[<p>On my way to work this morning I read an interesting article about the quality of data being produced by different systems and applications. While the article was emphasizing that the quality of the data should not be an IT problem (but management), our believe is that at the high volume, velocity and variety (the &ldquo;3Vs&rdquo; of big data) the data is produced today, the process of producing data is a shared responsibility between management and the IT department.</p>

<p>Since the emerging of Hadoop, the TCO of storing large amounts of data in HDFS is lower than ever before &ndash; and now it makes sense to store all the data an enterprise produces in order to find patterns, correlations and break the data silos &ndash; something which was very specific for different departments within an organization. Storing such an amount of data (structured, unstructured, logs, clickstream, etc) inevitable produces a &lsquo;bad&rsquo; data quality &ndash; but this depends on your point of view. For us data is just data &ndash; we don&rsquo;t want to qualify it &ndash; and has it&rsquo;s own intrinsic value, but the quality of it depends on the ETL process. When someone engages with our API and the xTract Spacetime platform, among the first step is the configuration of data sources, and the attached ETL processes. We offer an extremely sophisticated ETL process and the ability to &lsquo;clean&rsquo; the data (batch or streaming) while arrives into xTract Spacetime, but we always suggest our customers to keep the raw data as well.</p>

<p>During the architecture of the xTract Spacetime platform we have tried and PoCd different ETL frameworks and implementations &ndash; and we choose <a href="https://github.com/kite-sdk/kite/tree/master/kite-morphlines">Kite Morphlines</a> being at the core of our ETL process. Morphlines is an open source framework that reduces the time and skills necessary to build and change Hadoop ETL stream processing applications that extract, transform and load data into Apache Solr, HBase, HDFS, Enterprise Data Warehouses, or Analytic Online Dashboards.</p>

<!-- more -->


<p>Since runs on Hadoop, scalability is not a problem &ndash; we have seen enterprises producing 50 terabytes data per day and missing the 24 hour ETL window, by not being able to scale horizontally their ETL processes. Morphlines is built on top of the Kite framework (a great framework for making easier to build systems on top of the Hadoop), and it&rsquo;s extremely easy to extend. We would like to show and give you examples about how to use and create a Morphlines Command to implement your custom transformation (if the many existing ones does not fit your requirement).</p>

<p>The implementation of a Command starts with implementing a CommandBuilder</p>

<p>Actually a new morphline command implementation is not that hard. You have to implement a builder class (see below), define the name of the command and  extend the AbstractCommand base class. That simple.</p>

<p>``` java ToLowerCaseBuilder implements CommandBuilder</p>

<p>@Override
  public Collection<String> getNames() {</p>

<pre><code>return Collections.singletonList("toLowerCase");
</code></pre>

<p>  }</p>

<p>```</p>

<p>``` java toLowerCase Morphlines command</p>

<p>@Override
protected boolean doProcess(Record record) {
  ListIterator iter = record.get(fieldName).listIterator();
  while (iter.hasNext()) {</p>

<pre><code>iter.set(transformFieldValue(iter.next()));
</code></pre>

<p>  }</p>

<pre><code>return super.doProcess(record);
</code></pre>

<p>}</p>

<p>  private Object transformFieldValue(Object value) {</p>

<pre><code>return value.toString().toLowerCase(locale);
</code></pre>

<p>  }</p>

<p>```</p>

<p>To configure your new morhline command</p>

<p>``` java toLowerCase config</p>

<p>morphlines : [
  {
   id : morphline1</p>

<pre><code>   importCommands : ["com.sequenceiq.samples.**"]

   commands : [
     {
       toLowerCase {
         field : Name
         locale : en_us
       }
     }
   ]
</code></pre>

<p>  }
]</p>

<p>```</p>

<p>There is a custom tester tool which waiting a file as an input, a file as a config and an expected output. Among our plans is to build a UI on top of Kite Morphlines as well &ndash; part of our product stack. While we consider the Morhplines configuration, and defining the transformations simple and easy to use, many of our users might prefer a custom UI whee you can define your own ETL process visually.</p>

<p>Thatâ€™s it. You can find the samples at our <a href="https://github.com/sequenceiq/sequenceiq-samples">GitHub page</a>.
Hope you enjoy it, let us know if you need help or have any questions.</p>
]]></content>
  </entry>
  
</feed>
